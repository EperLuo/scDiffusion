{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from VAE.VAE_model import VAE\n",
    "from torch.autograd import Variable\n",
    "import celltypist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_VAE():\n",
    "    autoencoder = VAE(\n",
    "        num_genes=18996,\n",
    "        device='cuda',\n",
    "        seed=0,\n",
    "        loss_ae='mse',\n",
    "        hidden_dim=128,\n",
    "        decoder_activation='ReLU',\n",
    "    )\n",
    "    autoencoder.load_state_dict(torch.load('/data1/lep/Workspace/guided-diffusion/VAE/checkpoint/muris_scimilarity_lognorm_finetune/model_seed=0_step=150000.pt'))\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11401, 18996)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad('/data1/lep/Workspace/guided-diffusion/data/tabula_muris/all.h5ad')\n",
    "adata.var_names_make_unique()\n",
    "sc.pp.filter_cells(adata, min_genes=10)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "gene_names = adata.var_names\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "cell_data = adata.X.toarray()[::5]\n",
    "\n",
    "cell_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unconditional generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 18996)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the generated data path\n",
    "npzfile=np.load('/data1/lep/Workspace/guided-diffusion/output/muris_scimilarity.npz',allow_pickle=True)\n",
    "\n",
    "cell_gen_all = npzfile['cell_gen'][:10000]\n",
    "\n",
    "autoencoder = load_VAE()\n",
    "cell_gen_all = autoencoder(torch.tensor(cell_gen_all).cuda(),return_decoded=True).detach().cpu().numpy()\n",
    "ori = ad.AnnData(cell_gen_all, dtype=np.float32)\n",
    "cell_gen = ori.X\n",
    "cell_gen.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman= 0.9944149643330309\n",
      "pearson= 0.9986732924303006\n"
     ]
    }
   ],
   "source": [
    "print('spearman=',stats.spearmanr(cell_data.mean(axis=0), cell_gen.mean(axis=0)).correlation)\n",
    "print('pearson=',np.corrcoef(cell_data.mean(axis=0), cell_gen.mean(axis=0))[0][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    '''\n",
    "    å°†æºåŸŸæ•°æ®å’Œç›®æ ‡åŸŸæ•°æ®è½¬åŒ–ä¸ºæ ¸çŸ©é˜µ, å³ä¸Šæ–‡ä¸­çš„K\n",
    "    Params: \n",
    "\t    source: æºåŸŸæ•°æ®(n * len(x))\n",
    "\t    target: ç›®æ ‡åŸŸæ•°æ®(m * len(y))\n",
    "\t    kernel_mul: \n",
    "\t    kernel_num: å–ä¸åŒé«˜æ–¯æ ¸çš„æ•°é‡\n",
    "\t    fix_sigma: ä¸åŒé«˜æ–¯æ ¸çš„sigmaå€¼\n",
    "\tReturn:\n",
    "\t\tsum(kernel_val): å¤šä¸ªæ ¸çŸ©é˜µä¹‹å’Œ\n",
    "    '''\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "\n",
    "    L2_distance = ((total0-total1)**2).sum(2) \n",
    "\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "\n",
    "    return sum(kernel_val)\n",
    "\n",
    "def mmd_rbf(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "        kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX + YY - XY -YX)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = np.concatenate((cell_data, cell_gen),axis=0)\n",
    "adata = ad.AnnData(adata, dtype=np.float32)\n",
    "adata.obs_names = [f\"true_Cell\" for i in range(cell_data.shape[0])]+[f\"gen_Cell\" for i in range(cell_gen.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0822)\n"
     ]
    }
   ],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "real = adata[adata.obs_names=='true_Cell'].obsm['X_pca'][::2][:5000] # can not be set too large, the kernel might fail\n",
    "gen = adata[adata.obs_names=='gen_Cell'].obsm['X_pca'][::2][:5000]\n",
    "X = torch.Tensor(real)\n",
    "Y = torch.Tensor(gen)\n",
    "X,Y = Variable(X), Variable(Y)\n",
    "print(mmd_rbf(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Youâ€™re trying to run this on 18996 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6955686406343145"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scib\n",
    "adata = np.concatenate((cell_data, cell_gen),axis=0)\n",
    "adata = ad.AnnData(adata, dtype=np.float32)\n",
    "adata.obs['batch'] = pd.Categorical([f\"true_Cell\" for i in range(cell_data.shape[0])]+[f\"gen_Cell\" for i in range(cell_gen.shape[0])])\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20)\n",
    "scib.me.ilisi_graph(adata, batch_key=\"batch\", type_=\"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "celltypist for conditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11401, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if not generated all type of cells, use the real cell to balance the batchnorm in the scimilarity\n",
    "adata_w = adata.copy()[::5].X.toarray()\n",
    "\n",
    "autoencoder = load_VAE()\n",
    "cell_w = autoencoder(torch.tensor(adata_w).cuda(),return_latent=True).detach().cpu().numpy()\n",
    "\n",
    "# concat this cell_w with cell_gen and send them to the autoencoder\n",
    "# cell_gen_all = autoencoder(torch.tensor(np.concatenate((cell_gen,cell_w),axis=0)).cuda(),return_decoded=True).cpu().detach().numpy()\n",
    "cell_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if generated all type of cells, combine them together\n",
    "cato = ['Bladder', 'Heart_and_Aorta', 'Kidney', 'Limb_Muscle', 'Liver',\n",
    "       'Lung', 'Mammary_Gland', 'Marrow', 'Spleen', 'Thymus', 'Tongue',\n",
    "       'Trachea']\n",
    "index = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "rf = []\n",
    "diffu_acc = []\n",
    "\n",
    "cell_gen_all = []\n",
    "gen_class = []\n",
    "\n",
    "for i in range(12):\n",
    "    npzfile=np.load(f'../output/muris_condi/muris_{i}_scimilarity_nodrop.npz',allow_pickle=True)\n",
    "    length = 1000\n",
    "    cell_gen_all.append(npzfile['cell_gen'][:int(length)])#.squeeze(1)\n",
    "\n",
    "    gen_class+=['gen '+cato[i]]*int(length)\n",
    "\n",
    "cell_gen_all = np.concatenate(cell_gen_all,axis=0)\n",
    "\n",
    "autoencoder = load_VAE()\n",
    "cell_gen_all = autoencoder(torch.tensor(cell_gen_all).cuda(),return_decoded=True).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n",
      "âš ï¸ Warning: invalid expression matrix, expect all genes and log1p normalized expression to 10000 counts per cell. The prediction result may not be accurate\n",
      "ðŸ”¬ Input data has 1000 cells and 18996 genes\n",
      "ðŸ”— Matching reference genes in the model\n",
      "ðŸ§¬ 18996 features used for prediction\n",
      "âš–ï¸ Scaling input data\n",
      "ðŸ–‹ï¸ Predicting labels\n",
      "âœ… Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bladder', 0.987), ('Heart_and_Aorta', 0.665), ('Kidney', 0.915), ('Limb_Muscle', 0.917), ('Liver', 0.992), ('Lung', 0.941), ('Mammary_Gland', 0.899), ('Marrow', 0.953), ('Spleen', 0.996), ('Thymus', 0.925), ('Tongue', 0.996), ('Trachea', 0.983)]\n"
     ]
    }
   ],
   "source": [
    "import celltypist\n",
    "\n",
    "accs = []\n",
    "for i in index:\n",
    "    cell = cell_gen_all[i*1000:(i+1)*1000]\n",
    "    ori = ad.AnnData(cell, dtype=np.float32)\n",
    "    ori.var_names = gene_names\n",
    "\n",
    "    ori.X = (ori.X>np.log1p(10000)) * (np.log1p(10000)-1e-6) + ori.X * (ori.X<np.log1p(10000))\n",
    "    \n",
    "    predictions = celltypist.annotate(ori, model = '../checkpoint_old/celltypist_muris_all_re2.pkl')\n",
    "    acc = (predictions.predicted_labels.squeeze(1).values == cato[i]).sum()/cell.shape[0]\n",
    "    # print(cato[i],acc)\n",
    "    accs.append((cato[i],acc))\n",
    "    diffu_acc.append(acc)\n",
    "print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def knn_classify(adata):\n",
    "    real = adata[adata.obs_names=='true_Cell'].X.toarray()#.obsm['X_pca']\n",
    "    sim = adata[adata.obs_names=='gen_Cell'].X.toarray()#.obsm['X_pca']#\n",
    "\n",
    "    data = np.concatenate((real,sim),axis=0)\n",
    "    label = np.concatenate((np.ones((real.shape[0])),np.zeros((sim.shape[0]))))\n",
    "\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "    \n",
    "    ##å°†è®­ç»ƒé›†åˆ‡åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "    X_train,X_val,y_train,y_val = train_test_split(data, label,\n",
    "                                                test_size = 0.3,random_state = 1)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    predicted_label = knn_classifier.predict(X_val)\n",
    "    # print((predicted_label==y_val).sum()/X_val.shape[0])\n",
    "    accuracy = accuracy_score(predicted_label, y_val)\n",
    "\n",
    "    # ç®—AUC\n",
    "    predicted_probabilities = knn_classifier.predict_proba(X_val)[:, 1]  \n",
    "    \n",
    "    # è®¡ç®—AUCï¼Œåªé€‚ç”¨äºŽäºŒåˆ†ç±»é—®é¢˜  \n",
    "    # AUCéœ€è¦çœŸå®žæ ‡ç­¾å’Œæ­£ç±»çš„é¢„æµ‹æ¦‚çŽ‡  \n",
    "    auc = roc_auc_score(y_val, predicted_probabilities)  \n",
    "    print(f\"AUC: {auc}, Accuracy: {accuracy}\") \n",
    "\n",
    "    return accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5050333892598806, Accuracy: 0.5016666666666667\n",
      "AUC: 0.5, Accuracy: 0.48091603053435117\n",
      "AUC: 0.5083612040133779, Accuracy: 0.5016666666666667\n",
      "AUC: 0.5066889632107023, Accuracy: 0.5016666666666667\n",
      "AUC: 0.5083612040133779, Accuracy: 0.5016666666666667\n",
      "AUC: 0.5066889632107023, Accuracy: 0.5066666666666667\n",
      "AUC: 0.5033444816053512, Accuracy: 0.5016666666666667\n",
      "AUC: 0.5083612040133779, Accuracy: 0.5016666666666667\n",
      "AUC: 0.500016666851854, Accuracy: 0.5016666666666667\n",
      "AUC: 0.5016722408026756, Accuracy: 0.5016666666666667\n",
      "AUC: 0.5050167224080268, Accuracy: 0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lep/anaconda3/envs/pytorch/lib/python3.8/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5016722408026756, Accuracy: 0.5016666666666667\n",
      "0.5006318914334182\n",
      "[0.5016666666666667, 0.48091603053435117, 0.5016666666666667, 0.5016666666666667, 0.5016666666666667, 0.5066666666666667, 0.5016666666666667, 0.5016666666666667, 0.5016666666666667, 0.5016666666666667, 0.505, 0.5016666666666667]\n",
      "[0.5050333892598806, 0.5, 0.5083612040133779, 0.5066889632107023, 0.5083612040133779, 0.5066889632107023, 0.5033444816053512, 0.5083612040133779, 0.500016666851854, 0.5016722408026756, 0.5050167224080268, 0.5016722408026756]\n"
     ]
    }
   ],
   "source": [
    "cato = ['Bladder', 'Heart_and_Aorta', 'Kidney', 'Limb_Muscle', 'Liver',\n",
    "       'Lung', 'Mammary_Gland', 'Marrow', 'Spleen', 'Thymus', 'Tongue',\n",
    "       'Trachea']\n",
    "knn_acc = []\n",
    "knn_auc = []\n",
    "cell_gen_all = []\n",
    "gen_class = []\n",
    "index2 = list(range(12))\n",
    "length_per_type = 1000\n",
    "\n",
    "for i in range(12):\n",
    "    npzfile=np.load(f'../output/muris_condi/muris_{i}_scimilarity_nodrop.npz',allow_pickle=True)\n",
    "    cell_gen_all.append(npzfile['cell_gen'][:length_per_type])\n",
    "    gen_class+=['gen '+cato[i]]*length_per_type\n",
    "cell_gen_all = np.concatenate(cell_gen_all,axis=0)\n",
    "# print(cell_gen_all.shape)\n",
    "\n",
    "autoencoder = load_VAE()\n",
    "cell_gen_all = autoencoder(torch.tensor(cell_gen_all).cuda(),return_decoded=True).cpu().detach().numpy()\n",
    "\n",
    "for i in range(12):\n",
    "    cell_diff = cell_gen_all[i*length_per_type:(i+1)*length_per_type]\n",
    "    ori = ad.AnnData(cell_diff, dtype=np.float32)\n",
    "    ori.var_names = gene_names\n",
    "\n",
    "    length = min(adata[adata.obs['celltype'] == cato[i]].X.toarray().shape[0],length_per_type)\n",
    "\n",
    "    adata1 = ad.concat((adata[adata.obs['celltype'] == cato[i]][:length],ori[:length]))\n",
    "    adata1.obs_names = [f\"true_Cell\" for i in range(length)]+[f\"gen_Cell\" for i in range(ori[:length].X.shape[0])]\n",
    "\n",
    "    sc.tl.pca(adata1, svd_solver='arpack')\n",
    "    acc, auc = knn_classify(adata1)\n",
    "    knn_acc.append(acc)\n",
    "    knn_auc.append(auc)\n",
    "print(np.mean(knn_acc))\n",
    "print(knn_acc)\n",
    "print(knn_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e7d83ca490bf73dc2547b00b7dbe02b2441b6a62bd03186d7df051bc6fb7973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
