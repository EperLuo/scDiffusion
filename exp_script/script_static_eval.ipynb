{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from VAE.VAE_model import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_VAE():\n",
    "    autoencoder = VAE(\n",
    "        num_genes=18996,\n",
    "        device='cuda',\n",
    "        seed=0,\n",
    "        hparams=\"\",\n",
    "        decoder_activation='ReLU',\n",
    "    )\n",
    "    autoencoder.load_state_dict(torch.load('/data1/lep/Workspace/guided-diffusion/VAE/checkpoint/muris_all/model_seed=0_step=800000.pt'))\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/lep/anaconda3/envs/pytorch/lib/python3.8/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57004, 18996)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad('/data1/lep/Workspace/guided-diffusion/data/tabula_muris/all.h5ad')\n",
    "adata.var_names_make_unique()\n",
    "sc.pp.filter_cells(adata, min_genes=10)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "gene_names = adata.var_names\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "cell_data = adata.X.toarray()#[:10000]\n",
    "\n",
    "cell_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57000, 18996)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the generated data path\n",
    "npzfile=np.load('/data1/lep/Workspace/guided-diffusion/data/new_version/muris_all.npz',allow_pickle=True)\n",
    "\n",
    "cell_gen_all = npzfile['cell_gen']\n",
    "\n",
    "autoencoder = load_VAE()\n",
    "cell_gen_all = autoencoder(torch.tensor(cell_gen_all).cuda(),return_decoded=True).detach().cpu().numpy()\n",
    "ori = ad.AnnData(cell_gen_all, dtype=np.float32)\n",
    "cell_gen = ori.X\n",
    "cell_gen.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman= 0.9324554384174221\n",
      "pearson= 0.9880028185723689\n"
     ]
    }
   ],
   "source": [
    "print('spearman=',stats.spearmanr(cell_data.mean(axis=0), cell_gen.mean(axis=0)).correlation)\n",
    "print('pearson=',np.corrcoef(cell_data.mean(axis=0), cell_gen.mean(axis=0))[0][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "celltypist for conditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔬 Input data has 1000 cells and 18996 genes\n",
      "🔗 Matching reference genes in the model\n",
      "🧬 18996 features used for prediction\n",
      "⚖️ Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93\n"
     ]
    }
   ],
   "source": [
    "import celltypist\n",
    "\n",
    "cato = ['Bladder', 'Heart_and_Aorta', 'Kidney', 'Limb_Muscle', 'Liver',\n",
    "       'Lung', 'Mammary_Gland', 'Marrow', 'Spleen', 'Thymus', 'Tongue',\n",
    "       'Trachea']\n",
    "\n",
    "rf = []\n",
    "diffu_acc = []\n",
    "\n",
    "for i in range(12):\n",
    "    npzfile=np.load('/data1/lep/Workspace/guided-diffusion/data/new_version/muris_all2_'+str(i)+'.npz',allow_pickle=True)\n",
    "    cell_gen_all = npzfile['cell_gen'][:1000]\n",
    "    autoencoder = load_VAE()\n",
    "    batch = []\n",
    "    for j in range(18):\n",
    "        batch.append(autoencoder(torch.tensor(cell_gen_all[j*500:(j+1)*500]).cuda(),return_decoded=True).cpu().detach().numpy())\n",
    "    cell_gen_all = np.concatenate(batch)\n",
    "    ori = ad.AnnData(cell_gen_all, dtype=np.float32)\n",
    "    ori.var_names = gene_names\n",
    "\n",
    "    sc.pp.normalize_total(ori,1e4)\n",
    "    sc.pp.log1p(ori)\n",
    "    predictions = celltypist.annotate(ori, model = '/data1/lep/Workspace/guided-diffusion/checkpoint/celltypist_muris_all_re2.pkl')\n",
    "    acc = (predictions.predicted_labels.squeeze(1).values==cato[i]).sum()/1000\n",
    "    diffu_acc.append(acc)\n",
    "    print(acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    '''\n",
    "    将源域数据和目标域数据转化为核矩阵, 即上文中的K\n",
    "    Params: \n",
    "\t    source: 源域数据(n * len(x))\n",
    "\t    target: 目标域数据(m * len(y))\n",
    "\t    kernel_mul: \n",
    "\t    kernel_num: 取不同高斯核的数量\n",
    "\t    fix_sigma: 不同高斯核的sigma值\n",
    "\tReturn:\n",
    "\t\tsum(kernel_val): 多个核矩阵之和\n",
    "    '''\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "\n",
    "    L2_distance = ((total0-total1)**2).sum(2) \n",
    "\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "\n",
    "    return sum(kernel_val)\n",
    "\n",
    "def mmd_rbf(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "        kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX + YY - XY -YX)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = np.concatenate((cell_data, cell_gen),axis=0)\n",
    "adata = ad.AnnData(adata, dtype=np.float32)\n",
    "adata.obs_names = [f\"true_Cell\" for i in range(cell_data.shape[0])]+[f\"gen_Cell\" for i in range(cell_gen.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0629)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "real = adata[adata.obs_names=='true_Cell'].obsm['X_pca'][:10000]\n",
    "gen = adata[adata.obs_names=='gen_Cell'].obsm['X_pca'][:10000]\n",
    "X = torch.Tensor(real)\n",
    "Y = torch.Tensor(gen)\n",
    "X,Y = Variable(X), Variable(Y)\n",
    "print(mmd_rbf(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You’re trying to run this on 18996 dimensions of `.X`, if you really want this, set `use_rep='X'`.\n",
      "         Falling back to preprocessing with `sc.pp.pca` and default params.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8841768000117711"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scib\n",
    "adata = np.concatenate((cell_data, cell_gen),axis=0)\n",
    "adata = ad.AnnData(adata, dtype=np.float32)\n",
    "adata.obs['batch'] = pd.Categorical([f\"true_Cell\" for i in range(cell_data.shape[0])]+[f\"gen_Cell\" for i in range(cell_gen.shape[0])])\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20)\n",
    "scib.me.ilisi_graph(adata, batch_key=\"batch\", type_=\"knn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e7d83ca490bf73dc2547b00b7dbe02b2441b6a62bd03186d7df051bc6fb7973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
